{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03),\n",
    "                  0, \n",
    "                  0.001)\n",
    "\n",
    "def featureTracking(prev_img, next_img, prev_pts, None, lk_params):\n",
    "    term_crit = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_COUNT, 30, 0.1)\n",
    "    \n",
    "    # calculate optical flow\n",
    "    next_pts, status, error = cv2.calcOpticalFlowPyrLK(prev_img, next_img, prev_pts, **lk_params)\n",
    "    \n",
    "    #TODO: get rid of poins which are outside the frame\n",
    "    \n",
    "    return(next_pts, status, error)\n",
    "\n",
    "#uses FAST as of now, modify parameters as necessary\n",
    "def featureDetection_1(img):\n",
    "    fast_threshold = 20\n",
    "    nonmaxSuppression = True\n",
    "    \n",
    "    # Initiate FAST object with default values\n",
    "    fast = cv2.FastFeatureDetector()\n",
    "    \n",
    "    # Disable nonmaxSuppression\n",
    "    fast.setBool('nonmaxSuppression',0)\n",
    "    fast.setInt('threshold', 20)\n",
    "\n",
    "    # find and draw the keypoints\n",
    "    points1 = fast.detect(img,None)\n",
    "    \n",
    "    return pts\n",
    "\n",
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict( maxCorners = 1000,\n",
    "                       qualityLevel = 0.3,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7 )\n",
    "\n",
    "def featureDetection_2(img, feature_params):\n",
    "    pts = cv2.goodFeaturesToTrack(img, mask = None, **feature_params)\n",
    "    return pts\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read consecutive frames\n",
    "\n",
    "prev_img\n",
    "next_img\n",
    "\n",
    "# Convert to grayscale\n",
    "\n",
    "\n",
    "# feature detection, tracking\n",
    "prev_pts = featureDetection_1(prev_img)\n",
    "next_pts, status, error = featureTracking(prev_img, next_img, prev_pts, lk_params)\n",
    "\n",
    "# Intrinsic/ Extrinsic parameters\n",
    "focal = 718.8560\n",
    "pp = [607.1928, 185.2157]\n",
    "\n",
    "\n",
    "pts1 = np.int32(prev_pts)\n",
    "pts2 = np.int32(next_pts)\n",
    "F, mask = cv2.findFundamentalMat(pts1,pts2,cv2.FM_LMEDS)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:car]",
   "language": "python",
   "name": "conda-env-car-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
